# ğŸ§  Clinical Summarization with Small Language Models

Este proyecto explora cÃ³mo aprovechar **Modelos de Lenguaje PequeÃ±os (SLMs)** para generar resÃºmenes automÃ¡ticos de historias clÃ­nicas reales.  
En lugar de depender de modelos gigantes como GPT-4, se optimizan modelos mÃ¡s ligeros usando estrategias avanzadas de prompting, **fine-tuning**, y **RAG (Retrieval-Augmented Generation)**.

---

## ğŸš€ Â¿QuÃ© hace este proyecto?

ğŸ“„ âœ ğŸ©º **Convierte historias clÃ­nicas largas y desorganizadas en resÃºmenes claros y Ãºtiles.**

Para lograrlo, se desarrollÃ³ una pipeline completa con:

- Comparativa de varios **SLMs**, evaluando calidad de resumen y tiempos de inferencia.
- AplicaciÃ³n de **prompting paso a paso** para mejorar la coherencia.
- ImplementaciÃ³n de una arquitectura **RAG con mÃºltiples preguntas** para entender mejor el contexto mÃ©dico.
- Ajuste fino (**fine-tuning**) del modelo LLaMA 3.2.
- Desarrollo de una **aplicaciÃ³n web interactiva** para generar resÃºmenes en tiempo real.

---

## âš™ï¸ TecnologÃ­as principales

- ğŸ§  Inferencia: Python Â· PyTorch Â· Hugging Face Â· Ollama  
- ğŸ” RecuperaciÃ³n y Ajuste Fino: ChromaDB Â· Unsloth 
- ğŸŒ Web: FastAPI (backend) + JavaScript (frontend)  
- ğŸ’» Hardware: GPU RTX 3050 Laptop

---

## ğŸ’» Vista previa de la aplicaciÃ³n

![Web app de generaciÃ³n de resÃºmenes clÃ­nicos](doc/tex-project/images/app.png)

La aplicaciÃ³n permite introducir una historia clÃ­nica y obtener un resumen automÃ¡tico de manera sencilla.

---

Este proyecto demuestra que los SLMs, con una buena estrategia, pueden ser una soluciÃ³n viable para tareas complejas como el resumen clÃ­nico, reduciendo costes y requisitos computacionales.



